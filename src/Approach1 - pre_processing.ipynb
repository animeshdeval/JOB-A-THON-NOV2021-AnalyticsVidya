{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from functools import reduce\n",
    "from pandas_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Overview\n",
    "\n",
    "1. The data is incremental with respect to the date. The dataset is for full calender year of 2016 and 2017. \n",
    "2. Since the predictions are to be provided for 2 quarters of 2018, the data will be split from Jan 2016 upto June 2017 \n",
    "for training and July 2017 to Dec 2017 to create target variable. So those employees leaving the company from July 2017 \n",
    "to Dec 2017 will be labeled as 1. The training data will be filtered for all employees except those who have already \n",
    "churned before July 2017 because those such employees will neither be labelled as 1 nor 0.\n",
    "3. The developed model will be used to predict Jan 2018 to June 2018 attrition, there will be a stride of 6 months \n",
    "in the training data. Thus the training data for prediction will be from July 2016 to Dec 2017. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(df, start_date, cut_off_date, last_date):\n",
    "    '''\n",
    "    inputs:\n",
    "    dataset to be processed\n",
    "    start_date: the start date of the 'LastWorkingDate' \n",
    "    cut_off_date: the end date of the training dataset \n",
    "    last_date: end date of validation/test dataset\n",
    "    \n",
    "    output:\n",
    "    data: a merge of several dataframes engineered from raw dataset\n",
    "    1. df_demograph: dataframe of unique values for demographic data\n",
    "    2. df_salary_change: dataframe engineered from 'Salary'to derive the 'increment' column\n",
    "    3. df_promotion: dataframe engineered from 'Joining Designation' and 'Designation' to derive 'Promotion'\n",
    "    4. df_total: dataframe engineered to derive the total business-value of the employee\n",
    "    5. df_average: dataframe engineered to derive the total business-value of the employee\n",
    "    6. df_working_days:\n",
    "    7. df_reporting:                                                                    \n",
    "    8. df_target:                                                                   \n",
    "                                                                        \n",
    "    \n",
    "    \n",
    "    Promotion forms a significant part in establishing job performance for\n",
    "    the employer and job satisfaction for the employee. Also if any increase in the designation was calculated based\n",
    "    on joining designation and the designation.\n",
    "    4. df_total: A part of Feature Engineering. It is the total business value generated by the hardworking employee\n",
    "    throughout his tenure or the cutoff date\n",
    "    5. df_average:  A part of Feature Engineering. average_business_value, average_salary and average_quarterly_rating \n",
    "    generated by the employee throughout his tenure or the cutoff date\n",
    "    6. df_reporting: A part of Feature Engineering. Total reporting count of each employee\n",
    "    7. df_working_days: A part of Feature Engineering. Total number of employment days for each employee. If the employee\n",
    "    has last working day, then the days were counted from joining date to last working day else joining date to cutoff date\n",
    "    \n",
    "    Target varibale is created using cutoff date, to prepare the training data, cutoff date will be 1 July 2017 that is\n",
    "    all employees who had attrition from 1 July 2017 to 31 Dec 2017 will be labeled as 1. Those who have not yet given\n",
    "    their resignation till 1 July 2017 will be tagged as 0. \n",
    "       \n",
    "    \n",
    "    '''\n",
    "    # Filtering data suitable for creating training data\n",
    "    df = df[df['MMM-YY']>start_date]\n",
    "    df = df[df['MMM-YY']<cut_off_date]    \n",
    "#     df = df[(df['Dateofjoining']<cut_off_date)]  \n",
    "    \n",
    "    # Demographic dataset creation for each employee\n",
    "    df_demograph = df[['Emp_ID', \n",
    "                   'Age', \n",
    "                   \"Gender\", \n",
    "                   \"City\", \n",
    "                   \"Education_Level\"]].groupby('Emp_ID').max().reset_index()\n",
    "    \n",
    "    # Feature Engineer - min_salary, max_salary and increment\n",
    "    df_salary_min = df.groupby('Emp_ID').min()['Salary'].reset_index()\n",
    "    df_salary_min.columns =['Emp_ID', \n",
    "                            'Salary_min']\n",
    "    df_salary_max = df.groupby('Emp_ID').max()['Salary'].reset_index()\n",
    "    df_salary_max.columns =['Emp_ID', \n",
    "                            'Salary_max']    \n",
    "    df_salary_change = pd.merge(df_salary_min, \n",
    "                                df_salary_max, \n",
    "                                how = 'inner', \n",
    "                                on = 'Emp_ID')\n",
    "    df_salary_change['Increment'] = ((df_salary_change['Salary_max'] - df_salary_change['Salary_min'])/df_salary_change['Salary_min'] *100).astype(int)\n",
    "    \n",
    "    # Feature Engineering - Promotion if there is any increase in the designation. The more the number, higher the promotion\n",
    "    df_promotion = df\n",
    "    df_promotion[\"promotion\"] = np.where(df_promotion['Joining Designation']==df_promotion['Designation'], 0, \n",
    "                                     df_promotion['Designation'] - df_promotion['Joining Designation'])\n",
    "    df_promotion = df_promotion[['Emp_ID',\n",
    "                                 'Joining Designation', \n",
    "                                 'Designation', \n",
    "                                 'promotion']].groupby(\"Emp_ID\").max().reset_index()\n",
    "    \n",
    "    # Feature Engineering - total business value generated by the employee throughout his tenure or the cutoff date\n",
    "    df_total = df.groupby('Emp_ID').sum()\n",
    "    df_total = df_total[\"Total Business Value\"].reset_index()\n",
    "    df_total = df_total.set_axis(['Emp_ID', \n",
    "                                  'total_business_value'], \n",
    "                                 axis=1, \n",
    "                                 inplace=False)\n",
    "    \n",
    "    # Feature Engineering - average business value, average salary and average quarterly rating generated by the \n",
    "    #employee throughout his tenure or the cutoff date\n",
    "    \n",
    "    df_average = df.groupby('Emp_ID').mean()\n",
    "    df_average = df_average[['Salary', \n",
    "                             'Total Business Value', \n",
    "                             'Quarterly Rating']].reset_index()\n",
    "    df_average = df_average.set_axis(['Emp_ID', \n",
    "                                      'avg_salary', \n",
    "                                      'avg_business_value', \n",
    "                                      'avg_quartely_rating'], \n",
    "                                     axis=1, \n",
    "                                     inplace=False)\n",
    "    \n",
    "    # Feature Engineering - total reporting count by each employee\n",
    "    df_reporting = df.groupby(['Emp_ID']).count()[['MMM-YY']].reset_index()\n",
    "    df_reporting.columns = [\"Emp_ID\", \n",
    "                            \"total_reportings\"]\n",
    "    \n",
    "    # Feature Engineering - total working days by each employee\n",
    "    df_working_days = df.groupby(['Emp_ID']).max().reset_index()\n",
    "    df_working_days['number_employment_days'] = np.where(df_working_days['LastWorkingDate']<cut_off_date, \n",
    "                                                          df_working_days['LastWorkingDate'] - df_working_days[\"Dateofjoining\"],\n",
    "                                                          cut_off_date - df_working_days[\"Dateofjoining\"])\n",
    "    df_working_days = df_working_days[['Emp_ID',  \n",
    "                                       \"number_employment_days\"]]\n",
    "\n",
    "    data = reduce(lambda x,y: pd.merge(x,y, on='Emp_ID', how='inner'), [df_demograph, \n",
    "                                                                        df_average, \n",
    "                                                                        df_working_days, \n",
    "                                                                        df_promotion, \n",
    "                                                                        df_salary_change, \n",
    "                                                                        df_total, \n",
    "                                                                        df_reporting])    \n",
    "    data[\"business_value_index\"] = round(data[\"total_business_value\"]/data[\"number_employment_days\"].dt.days.astype('int16'),2)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data\n",
    "The dataframe is loaded as well as three dates are to be supplied\n",
    "\n",
    "1. start_date: This date will provide the starting date for the data to be preprocessed. \n",
    "    In the given project, the training data is for 1.5 years and target of 0.5 years. \n",
    "    The data will roll every 0.5 years for the new predictions. So the start date can be mentioned accordingly\n",
    "2. cut_off_date: This date will provide the training data cutoff date, beyond which data will not be considered\n",
    "3. last_date: This date provides the overall last date of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exploratory analysis of demographic data on the basis of full data available. Thus the cutoff date considered here is 1 July 2017 and start_date is 31 Dec 2015. Thus attrition of all employees (irrespective of their lat working day) are considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('D:/History/AV/attrition_data_hackathon/data/train_MpHjUjU.csv')\n",
    "# df[['MMM-YY','Dateofjoining', 'LastWorkingDate']] = df[['MMM-YY',\n",
    "#                                                         'Dateofjoining', \n",
    "#                                                         'LastWorkingDate']].apply(pd.to_datetime, \n",
    "#                                                                                   format='%Y-%m-%d')\n",
    "# start_date = np.datetime64(datetime.datetime(2015,12,31))\n",
    "# cut_off_date = np.datetime64(datetime.datetime(2018,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data_preprocess(df, start_date, cut_off_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sns.scatterplot(data['Age'], data['target'])\n",
    "# plt.figure(figsize=(8,5))\n",
    "# sns.catplot(x='target',y='Age',data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.crosstab(data['target'],data['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap(pd.crosstab(data['target'],data['Gender']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.crosstab(data['target'],data['Education_Level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sns.heatmap(pd.crosstab(data['target'],data['Education_Level']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (pd.crosstab(data['target'],data['City'])).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.heatmap(pd.crosstab(data['target'],data['City']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "1. Age: Almost equal distribution between churn and non-churners\n",
    "2. Gender: Both females and males have higher attrition rate\n",
    "3. Education level: All levels has higher attrition rate\n",
    "4. City: there are few cities C10, C12, C16, C22, C24, C26, C27, C29, C3, C5 who has almost equal distribution of churners vs non-churners\n",
    "\n",
    "##### Conclusion: Thus cities needs to be one-hot coded which could have impact on attrition rate. Rest other demographic data may not be useful in predicting attrition rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory analysis of other features. \n",
    "\n",
    "The target variable will be created based on cutoff date 1 July 2017 and start_date is 31 Dec 2015. Thus attrition of employees post 1 July will be labelled as 1, while others were tagged as 0. The data will be filtered using cutoff date and hence employees whos attrition is less than 1 July will not be considered and those employees whos joining date is beyong 1 July will not be considered in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:/History/AV/attrition_data_hackathon/data/train_MpHjUjU.csv')\n",
    "df[['MMM-YY','Dateofjoining', 'LastWorkingDate']] = df[['MMM-YY',\n",
    "                                                        'Dateofjoining', \n",
    "                                                        'LastWorkingDate']].apply(pd.to_datetime, \n",
    "                                                                                  format='%Y-%m-%d')\n",
    "start_date = np.datetime64(datetime.datetime(2016,1,1))\n",
    "cut_off_date = np.datetime64(datetime.datetime(2017,1,1))\n",
    "last_date = np.datetime64(datetime.datetime(2017,7,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Spice\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n",
      "<ipython-input-134-802caf0bce7b>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_target['target'] = np.where((df_target['LastWorkingDate']>cut_off_date) & (df_target['LastWorkingDate']<last_date), 1, 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1183\n",
       "1     285\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering data suitable for creating training data\n",
    "df_target = df \n",
    "df_target = df[df['MMM-YY']>cut_off_date]# & (df['LastWorkingDate']<last_date)]\n",
    "df_target = df[df['MMM-YY']<last_date]\n",
    "df_target = df[df['Dateofjoining']<cut_off_date]\n",
    "df_target.drop(df_target[df_target['LastWorkingDate']<cut_off_date].index, inplace=True)\n",
    "df_target['target'] = np.where((df_target['LastWorkingDate']>cut_off_date) & (df_target['LastWorkingDate']<last_date), 1, 0)\n",
    "\n",
    "df_target = df_target[['Emp_ID',\n",
    "                        'Dateofjoining',\n",
    "                        'LastWorkingDate',\n",
    "                        'target']]\n",
    "\n",
    "df_target = df_target.groupby('Emp_ID').max()\n",
    "df_target['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_preprocess(df, start_date, cut_off_date, last_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data,df_target, on=\"Emp_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Emp_ID', 'Age', 'Gender', 'City', 'Education_Level', 'avg_salary',\n",
       "       'avg_business_value', 'avg_quartely_rating', 'number_employment_days',\n",
       "       'Joining Designation', 'Designation', 'promotion', 'Salary_min',\n",
       "       'Salary_max', 'Increment', 'total_business_value', 'total_reportings',\n",
       "       'business_value_index', 'Dateofjoining', 'LastWorkingDate', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Age', 'Gender', 'Education_Level', 'Dateofjoining', 'LastWorkingDate', 'City'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['Emp_ID', 'number_employment_days', 'Designation', 'promotion', 'Increment', 'business_value_index', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile_report = ProfileReport(data, title=\"Pandas Profiling Report\")\n",
    "# profile_report.to_widgets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plots vs churn\n",
    "<br> 'Emp_ID', 'Age', 'Gender', 'City', 'Education_Level'\n",
    "<br> 'avg_business_value', 'avg_quartely_rating', 'number_employment_days'\n",
    "<br> 'promotion'\n",
    "<br> 'Increment'\n",
    "<br> 'total_reportings'\n",
    "<br> 'business_value_index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### columns to be selected\n",
    "avg_business_value, \n",
    "avg_quartely_rating,\n",
    "Joining Designation,\n",
    "Designation,\n",
    "promotion,\n",
    "Increment,\n",
    "total_reportings,\n",
    "business_value_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate analysis by scatterplot of avg_business_value, avg_salary and target showed that less the business_value, more is the churn\n",
    "sns.scatterplot(data['avg_business_value'], data['avg_quartely_rating'], hue = data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low business_value_index is clearly associated with churners. That means people bringing low business value per working day are likely to be churned\n",
    "sns.barplot(data['target'], data['business_value_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low avg_salary can lead to churners\n",
    "\n",
    "sns.barplot(data['churn'], data['avg_salary'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total low reportings are associated with churners\n",
    "sns.barplot(data['churn'], data['total_reportings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total low reportings are associated with churners\n",
    "sns.barplot(data['churn'], data['avg_quartely_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low avg_salary can lead to churners\n",
    "\n",
    "sns.heatmap(pd.crosstab(data['target'],data['promotion']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data['target'],data['promotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data['target'],data['Designation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data['target'],data['Joining Designation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data['target'],data['total_reportings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data['target'],data['Increment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data['target'],data['avg_quartely_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.catplot(x=\"churn\", y=\"avg_quartely_rating\", data=data) #jitter=False,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"churn\", y=\"avg_quartely_rating\", kind=\"swarm\", data=data) #jitter=False,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['number_employment_days'] = data['number_employment_days'].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Age', 'Gender', 'Education_Level', 'Dateofjoining', 'LastWorkingDate', 'City'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['business_value_index'] = data['business_value_index'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['Emp_ID', 'number_employment_days', 'Designation', 'promotion', 'Increment', 'business_value_index', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1179\n",
       "1     282\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor    \n",
    "\n",
    "def calculate_vif_(X, thresh=5.0):\n",
    "    variables = list(range(X.shape[1]))\n",
    "    dropped = True\n",
    "    while dropped:\n",
    "        dropped = False\n",
    "        vif = [variance_inflation_factor(X.iloc[:, variables].values, ix)\n",
    "               for ix in range(X.iloc[:, variables].shape[1])]\n",
    "\n",
    "        maxloc = vif.index(max(vif))\n",
    "        if max(vif) > thresh:\n",
    "            print('dropping \\'' + X.iloc[:, variables].columns[maxloc] +\n",
    "                  '\\' at index: ' + str(maxloc))\n",
    "            del variables[maxloc]\n",
    "            dropped = True\n",
    "\n",
    "    print('Remaining variables:')\n",
    "    print(X.columns[variables])\n",
    "    return X.iloc[:, variables]\n",
    "\n",
    "# calculate_vif_(x_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Spice\\anaconda3\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:193: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "C:\\Users\\Spice\\anaconda3\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1687: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping 'avg_salary' at index: 0\n",
      "dropping 'Joining Designation' at index: 3\n",
      "dropping 'Salary_min' at index: 5\n",
      "dropping 'avg_business_value' at index: 0\n",
      "dropping 'Salary_max' at index: 4\n",
      "dropping 'avg_quartely_rating' at index: 0\n",
      "dropping 'total_reportings' at index: 5\n",
      "dropping 'total_business_value' at index: 4\n",
      "Remaining variables:\n",
      "Index(['number_employment_days', 'Designation', 'promotion', 'Increment',\n",
      "       'business_value_index'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_employment_days</th>\n",
       "      <th>Designation</th>\n",
       "      <th>promotion</th>\n",
       "      <th>Increment</th>\n",
       "      <th>business_value_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-8531.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2075.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14898.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1679</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3668.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>91</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1539</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4837.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>419</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6190.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>335</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1700.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1461 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      number_employment_days  Designation  promotion  Increment  \\\n",
       "0                         78            1          0          0   \n",
       "1                         25            2          0          0   \n",
       "2                         58            1          0          0   \n",
       "3                        175            1          0          0   \n",
       "4                       1679            4          3          0   \n",
       "...                      ...          ...        ...        ...   \n",
       "1456                      91            2          0          0   \n",
       "1457                      92            1          0          0   \n",
       "1458                    1539            3          1          0   \n",
       "1459                     419            2          0          0   \n",
       "1460                     335            1          0          0   \n",
       "\n",
       "      business_value_index  \n",
       "0                 -8531.79  \n",
       "1                     0.00  \n",
       "2                  2075.17  \n",
       "3                 14898.17  \n",
       "4                  3668.69  \n",
       "...                    ...  \n",
       "1456                  0.00  \n",
       "1457                  0.00  \n",
       "1458               4837.80  \n",
       "1459               6190.95  \n",
       "1460               1700.72  \n",
       "\n",
       "[1461 rows x 5 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_vif_(X,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "target='target'\n",
    "primary_key = \"Emp_ID\"\n",
    "\n",
    "X = data.drop([target, primary_key],1)\n",
    "y = data[target]\n",
    "# Divide the training data given to train and validation data frames\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.to_csv('D:/History/AV/attrition_data_hackathon/data/x_train.csv',index=False)\n",
    "x_val.to_csv('D:/History/AV/attrition_data_hackathon/data/x_val.csv',index=False)\n",
    "y_train.to_csv('D:/History/AV/attrition_data_hackathon/data/y_train.csv',index=False)\n",
    "y_val.to_csv('D:/History/AV/attrition_data_hackathon/data/y_val.csv',index=False)\n",
    "# x_test.to_csv('D:/History/AV/attrition_data_hackathon/data/processed_data/x_train.csv/x_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
